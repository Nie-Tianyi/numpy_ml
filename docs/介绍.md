机器学习是让计算机自动寻找规律的学科，也是人工智能的基础。例如房价和面积的规律——通常来讲面积越大的房子，售价越高，并且存在简单的线性关系——假设该小区的房价为10000人民币/平方米，那么一个80平方的房子售价大概率在80万元上下。反的来说，机器学习算法可以通过过往该小区房子售价和面积的数据，推导出每平方米售价在1万元，进而能预测一个面积为120平米的房子售价大概在120万元。当然这是一个比较简单的例子，机器学习算法不仅能推导简单的关系，还能处理复杂的问题，例如房子的售价不仅与面积相关，还跟房间是否朝阳、装修是否老旧、房间内噪音多少等多个变量相关，机器学习算法同样能处理多个变量之间的复杂关系。甚至更复杂的，假设最终房价和一百多个变量相关，每个变量或多或少都影响着最终房价，机器学习算法同样能精准的推导每个变量和最终房价之间的关系，最终做出精准的预测。

现有的机器学习的算法根据训练的方式通常会被划分成三个大类，分别是：有监督学习（supervised-learning）、无监督学习（unsupervised-learning）以及强化学习（reinforcement-learning）。尽管被划分为了三个大类，各类中的算法既有交叉，也有互补。例如，著名的神经网络算法不仅在监督学习中用于预测，还在无监督学习中用于异常检测，也在强化学习中用于帮助机器人在未知的环境下做出决策。监督学习通常指我们在训练前准备好标注好的数据，然后用算法拟合数据（也可以叫做训练算法），最后再用训练好的模型用于预测。例如在监督学习中我们通常会准备很多条标注好的数据，例如我们想要预测房价，我们通常会准备以下数据：

| 面积（平方米） | 是否朝阳 | 噪音分贝（分贝） | 售价（万人民币） |
| --- | --- | --- | --- |
| 96 | 是 | 32 | 107  |
| 80 | 否 | 69 | 69 |
| ... | ... | ... | ... |


面积、是否朝阳、噪音分贝将是算法的输入，而售价则是算法的输出。这里想要预测的变量“售价”在数据集中是提前收集好的，这样的数据我们就可以用于训练算法，训练完算法后，我们就可将房屋的面积、是否朝阳、噪音分贝三个变量输入算法，最后算法会输出预测房屋的售价。监督学习在训练前通常要求研究人员手动标注数据，例如这里的“售价”变量。标注工作通常是一个枯燥乏味的“苦力活”，例如在计算机视觉中，标注数据通常需要研究人员手动框出图片中想要识别的物体，这通常耗费大量的人力和时间。常见的监督学习算法有分类算法、预测数据，如果将上例中的预测目标改为售价是否高于100万，预测结果只有“是”或者“不是”，上面的问题就会变成一个分类问题（更准确的说是一个二分类问题）。

无监督学习中我们通常没有所谓的“标注数据”，无监督学习可以帮助我们发现数据中不曾知道的规律。常见的无监督学习算法有聚类算法、异常检测。例如在聚类算法中，我们只需要将数据直接交给算法，接着算法会根据我们提前设定的规则，将数据分为符合直觉的多个类别。

强化学习能够让模型在不确定的环境中自主进化出完成任务的能力，适用于我们没法给出最优解的任务，于是我们让模型自主探索出如何完成目标。在强化学习中，我们会提前规定一系列的奖励和惩罚规则，然后让模型不断试错——如果模型做出更接近目标的动作，则奖励模型；如果模型做出的决策偏离了我们设定的目标，则惩罚模型。通过不断的奖励和惩罚，让神经网络模型学习如何自主完成我们规定的目标。

最常用的强化学习算法叫DQL（Deep Q-Learning，强化Q学习），DQL中的核心算法也是神经网络算法，神经网络的输入为环境中的各种数据，而输出则为我们的模型在这种环境中应该做出的决策。常见的强化学习应用包括让机器人、机器狗自主学习走路跑步，让火星车登陆火星后自主完成科研任务。最早开发机器狗的公司波士顿动力最开始就是使用强化学习算法来让机器狗学习如何走路、越障、甚至完成后空翻等杂技动作。

机器学习发展到今天远远不能用三个类别就简单概括所有算法，现有的机器学习算法通常使用多种算法结合在一起完成目标——例如有的大语言模型可能先使用监督学习预训练模型，然后再用强化学习强化模型完成任务的能力；或者是一个机器学习算法使用了多个模型算法，每个模型都用不同的方式训练而来，完成任务的时候同时使用多个模型共同决策。

机器学习的应用充斥着我们的生活，从几乎到处都有的人脸识别系统、语音转文字应用、信达雅的中英文翻译软件，到短视频的推荐算法、自动驾驶、以及火爆出圈的大语言模型，都是由一个个最基础的机器学习算法驱动。学习机器学习不仅能让你学习这些神奇的应用背后的原理，还能让你有机会亲手构建这些像魔法一样的应用，让你走在人工智能发展的最前沿。

